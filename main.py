import feedparser
import os  # 'os' ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
from notion_client import Client
import datetime
import sys # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¢…ë£Œë¥¼ ìœ„í•¨

# --- 1. ì„¤ì • (GitHub Actions Secretì—ì„œ ê°€ì ¸ì˜¤ë„ë¡ ìˆ˜ì •) ---
# ğŸ”‘ GitHub Actionsì˜ 'Secrets'ì— ì €ì¥ëœ ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
NOTION_API_KEY = os.environ.get('NOTION_API_KEY')
DATABASE_ID = os.environ.get('DATABASE_ID')

# ğŸ¤– API í‚¤ë‚˜ DB IDê°€ ì—†ìœ¼ë©´ ìŠ¤í¬ë¦½íŠ¸ ì¤‘ì§€
if not NOTION_API_KEY or not DATABASE_ID:
    print("âŒ ì˜¤ë¥˜: NOTION_API_KEY ë˜ëŠ” DATABASE_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1) # ìŠ¤í¬ë¦½íŠ¸ ë¹„ì •ìƒ ì¢…ë£Œ

# ğŸ¤– ë…¸ì…˜ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
notion = Client(auth=NOTION_API_KEY)

# --- 2. í•„í„°ë§í•  í‚¤ì›Œë“œ ëª©ë¡ ì •ì˜ ---
KEYWORDS = {
    "AI": ["AI", "ì¸ê³µì§€ëŠ¥", "ë”¥ëŸ¬ë‹", "ë¨¸ì‹ ëŸ¬ë‹", "LLM", "ìƒì„±í˜•", "ChatG"],
    "ë¬¸í™”/ì¶•ì œ": ["ë¬¸í™”", "ì¶•ì œ", "í˜ìŠ¤í‹°ë²Œ", "ì „ì‹œ", "ê³µì—°", "ì½˜ì„œíŠ¸", "ë®¤ì§€ì»¬", "ë¯¸ìˆ ê´€"],
    "ë¬¸í™”ì½˜í…ì¸ ": ["ì½˜í…ì¸ ", "ì›¹íˆ°", "ì˜í™”", "ë“œë¼ë§ˆ", "K-POP", "ê²Œì„", "ì• ë‹ˆë©”ì´ì…˜", "í•œë¥˜", "OTT"]
}

# --- 3. ìˆ˜ì§‘í•  RSS í”¼ë“œ ëª©ë¡ ì •ì˜ (í”¼ë“œ ì¶”ê°€ë¨) ---
RSS_FEEDS = {
    # --- ê¸°ì¡´ í”¼ë“œ ---
    "AI_ì¡°ì„ IT": "https://www.chosun.com/arc/outboundfeeds/rss/category/it-science/?outputType=xml",
    "ë¬¸í™”_SBS": "https://news.sbs.co.kr/news/SectionRssFeed.do?sectionId=08&plink=RSSREADER",
    "ë¬¸í™”_í•œê²¨ë ˆ": "http://www.hani.co.kr/rss/culture/",
    
    # --- AI ê´€ë ¨ ë‰´ìŠ¤ ì¶”ê°€ ---
    "AI_ì „ë¬¸(AIíƒ€ì„ì¦ˆ)": "https://www.aitimes.com/rss/all.xml",
    "AI_IT(ZDNet)": "https://www.zdnet.co.kr/rss/ittrend.xml",
    
    # --- ë¬¸í™”ì½˜í…ì¸  ê´€ë ¨ ë‰´ìŠ¤ ì¶”ê°€ ---
    "ì½˜í…ì¸ _ê²Œì„(ê²Œì„ë©”ì¹´)": "https://www.gamemeca.com/rss/all.xml",
    "ì½˜í…ì¸ _ì˜í™”(ì”¨ë„¤21)": "http://www.cine21.com/rss/news.xml",
    "ì½˜í…ì¸ _ì‚°ì—…(KOCCA)": "https://www.kocca.kr/kocca/bbs/rss.do?bbsId=B0000137&searchBbsId=B0000137"
}

# --- 4. [ìˆ˜ì •ë¨] ì¤‘ë³µ ì²´í¬ë¥¼ ìœ„í•´ ê¸°ì¡´ URL ê°€ì ¸ì˜¤ê¸° ---
# (ë…¸ì…˜ DBì˜ "ìˆ˜ì§‘ì¼", "URL" ì†ì„± ì´ë¦„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤)
def get_existing_urls(days_to_check=3):
    print(f"ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ìµœê·¼ {days_to_check}ì¼ê°„ì˜ ê¸°ì¡´ ê¸°ì‚¬ URLì„ ì¡°íšŒí•©ë‹ˆë‹¤...")
    existing_urls = set()
    start_date = (datetime.datetime.now() - datetime.timedelta(days=days_to_check)).strftime("%Y-%m-%d")

    try:
        response = notion.databases.query(
            database_id=DATABASE_ID,
            filter={"property": "ìˆ˜ì§‘ì¼", "date": {"on_or_after": start_date}},
            page_size=100
        )
        results = response.get("results", [])
        
        for page in results:
            properties = page.get("properties", {})
            url_data = properties.get("URL", {}) # ë…¸ì…˜ì˜ "URL" ì†ì„±
            if url_data and url_data.get("url"):
                existing_urls.add(url_data.get("url"))
                
        print(f"ì´ {len(existing_urls)}ê°œì˜ ê¸°ì¡´ URLì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return existing_urls
    except Exception as e:
        print(f"âŒ ê¸°ì¡´ URL ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return existing_urls

# --- 5. [ìˆ˜ì •ë¨] ë…¸ì…˜ ì—…ë¡œë“œ í•¨ìˆ˜ (ìš”ì•½ ì¶”ê°€) ---
# (ë…¸ì…˜ DBì˜ "ì œëª©", "URL", "ë¶„ë¥˜", "ìˆ˜ì§‘ì¼", "ìš”ì•½" ì†ì„± ì´ë¦„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤)
def add_to_notion(title, url, category, summary): # 'summary' ë§¤ê°œë³€ìˆ˜ ì¶”ê°€
    today_str = datetime.datetime.now().strftime("%Y-%m-%d")
    try:
        # ìš”ì•½(summary)ì´ ë„ˆë¬´ ê¸¸ ê²½ìš° 2000ì(API ì œí•œ)ë¡œ ìë¦„
        summary_text = summary[:2000] if summary else "ìš”ì•½ ì—†ìŒ"

        new_page = {
            "ì œëª©": {"title": [{"text": {"content": title}}]},
            "URL": {"url": url},
            "ë¶„ë¥˜": {"multi_select": [{"name": category}]},
            "ìˆ˜ì§‘ì¼": {"date": {"start": today_str}},
            "ìš”ì•½": {"rich_text": [{"text": {"content": summary_text}}]} # âœ¨ 'ìš”ì•½' ì†ì„± ì¶”ê°€
        }
        notion.pages.create(parent={"database_id": DATABASE_ID}, properties=new_page)
        print(f"âœ… [ì—…ë¡œë“œ ì„±ê³µ!] ì¹´í…Œê³ ë¦¬: {category} | ì œëª©: {title}")
    except Exception as e:
        print(f"âŒ [ì—…ë¡œë“œ ì‹¤íŒ¨] ì œëª©: {title} | ì˜¤ë¥˜: {e}")
        pass

# --- 6. [ìˆ˜ì •ë¨] ë©”ì¸ ì‹¤í–‰ ë¡œì§ (ìš”ì•½ ì „ë‹¬) ---
def fetch_and_filter_news():
    print("="*30)
    print("ğŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘ ë° í•„í„°ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("="*30)
    
    existing_urls = get_existing_urls(days_to_check=3) 
    total_uploaded = 0
    total_skipped = 0
    
    for category_guess, rss_url in RSS_FEEDS.items():
        feed = feedparser.parse(rss_url)
        print(f"\n--- [{category_guess}] ì¹´í…Œê³ ë¦¬ í”¼ë“œ í™•ì¸ ì¤‘... ---")
        if not feed.entries:
            print("  (ìˆ˜ì§‘ëœ ê¸°ì‚¬ ì—†ìŒ)")
            continue

        for item in feed.entries:
            title = item.title
            link = item.link
            
            if link in existing_urls:
                total_skipped += 1
                continue 

            summary = item.get("summary", "") # âœ¨ ìš”ì•½ë³¸ ê°€ì ¸ì˜¤ê¸°
            content_to_check = title + " " + summary
            
            found_category = None
            for category_name, keywords_list in KEYWORDS.items():
                if any(keyword.lower() in content_to_check.lower() for keyword in keywords_list):
                    found_category = category_name
                    break 
            
            if found_category:
                add_to_notion(title, link, found_category, summary) # âœ¨ 'summary' ì „ë‹¬
                existing_urls.add(link)
                total_uploaded += 1
            
    print("\n" + "="*30)
    print(f"ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ.")
    print(f"  - ì‹ ê·œ ì—…ë¡œë“œ: {total_uploaded}ê°œ")
    print(f"  - ì¤‘ë³µ ìŠ¤í‚µ: {total_skipped}ê°œ")
    print("="*30)

# --- ğŸš€ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ---
if __name__ == "__main__":
    fetch_and_filter_news()
