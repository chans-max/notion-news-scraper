import feedparser
import os
from notion_client import Client
import datetime
import sys

# --- 1. ì„¤ì • (GitHub Actions Secretì—ì„œ ê°€ì ¸ì˜¤ë„ë¡ ìˆ˜ì •) ---
NOTION_API_KEY = os.environ.get('NOTION_API_KEY')
DATABASE_ID = os.environ.get('DATABASE_ID')

if not NOTION_API_KEY or not DATABASE_ID:
    print("âŒ ì˜¤ë¥˜: NOTION_API_KEY ë˜ëŠ” DATABASE_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)

notion = Client(auth=NOTION_API_KEY)

# --- 2. í•„í„°ë§í•  í‚¤ì›Œë“œ ëª©ë¡ ì •ì˜ ---
KEYWORDS = {
    "AI": ["AI", "ì¸ê³µì§€ëŠ¥", "ë”¥ëŸ¬ë‹", "ë¨¸ì‹ ëŸ¬ë‹", "LLM", "ìƒì„±í˜•", "ChatG"],
    "ë¬¸í™”/ì¶•ì œ": ["ë¬¸í™”", "ì¶•ì œ", "í˜ìŠ¤í‹°ë²Œ", "ì „ì‹œ", "ê³µì—°", "ì½˜ì„œíŠ¸", "ë®¤ì§€ì»¬", "ë¯¸ìˆ ê´€"],
    "ë¬¸í™”ì½˜í…ì¸ ": ["ì½˜í…ì¸ ", "ì›¹íˆ°", "ì˜í™”", "ë“œë¼ë§ˆ", "K-POP", "ê²Œì„", "ì• ë‹ˆë©”ì´ì…˜", "í•œë¥˜", "OTT"]
}

# --- 3. ìˆ˜ì§‘í•  RSS í”¼ë“œ ëª©ë¡ ì •ì˜ ---
RSS_FEEDS = {
    "AI_ì¡°ì„ IT": "https://www.chosun.com/arc/outboundfeeds/rss/category/it-science/?outputType=xml",
    "ë¬¸í™”_SBS": "https://news.sbs.co.kr/news/SectionRssFeed.do?sectionId=08&plink=RSSREADER",
    "ë¬¸í™”_í•œê²¨ë ˆ": "http://www.hani.co.kr/rss/culture/",
    "AI_ì „ë¬¸(AIíƒ€ì„ì¦ˆ)": "https://www.aitimes.com/rss/all.xml",
    "AI_IT(ZDNet)": "https://www.zdnet.co.kr/rss/ittrend.xml",
    "ì½˜í…ì¸ _ê²Œì„(ê²Œì„ë©”ì¹´)": "https://www.gamemeca.com/rss/all.xml",
    "ì½˜í…ì¸ _ì˜í™”(ì”¨ë„¤21)": "http://www.cine21.com/rss/news.xml",
    "ì½˜í…ì¸ _ì‚°ì—…(KOCCA)": "https://www.kocca.kr/kocca/bbs/rss.do?bbsId=B0000137&searchBbsId=B0000137"
}

# --- 4. [ìˆ˜ì •ë¨] ì¤‘ë³µ ì²´í¬ë¥¼ ìœ„í•´ ê¸°ì¡´ URL ê°€ì ¸ì˜¤ê¸° ---
def get_existing_urls(days_to_check=3):
    print(f"ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ìµœê·¼ {days_to_check}ì¼ê°„ì˜ ê¸°ì¡´ ê¸°ì‚¬ URLì„ ì¡°íšŒí•©ë‹ˆë‹¤...")
    existing_urls = set()
    start_date = (datetime.datetime.now() - datetime.timedelta(days=days_to_check)).strftime("%Y-%m-%d")

    try:
        response = notion.databases.query(
            database_id=DATABASE_ID,
            filter={"property": "ìˆ˜ì§‘ì¼", "date": {"on_or_after": start_date}},
            page_size=100
        )
        results = response.get("results", [])
        
        for page in results:
            properties = page.get("properties", {})
            url_data = properties.get("URL", {}) # ë…¸ì…˜ì˜ "URL" ì†ì„±
            if url_data and url_data.get("url"):
                existing_urls.add(url_data.get("url"))
                
        print(f"ì´ {len(existing_urls)}ê°œì˜ ê¸°ì¡´ URLì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return existing_urls
    except Exception as e:
        print(f"âŒ ê¸°ì¡´ URL ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e} (ì¤‘ë³µ ì²´í¬ê°€ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        return existing_urls # ì˜¤ë¥˜ ì‹œ ë¹ˆ set ë°˜í™˜ (ì¤‘ë³µ ì €ì¥ë  ìˆ˜ ìˆìŒ)

# --- 5. [ìˆ˜ì •ë¨] ë…¸ì…˜ ì—…ë¡œë“œ í•¨ìˆ˜ (ìš”ì•½ ì¶”ê°€) ---
def add_to_notion(title, url, category, summary): 
    today_str = datetime.datetime.now().strftime("%Y-%m-%d")
    try:
        summary_text = summary[:2000] if summary else "ìš”ì•½ ì—†ìŒ"

        new_page = {
            "ì œëª©": {"title": [{"text": {"content": title}}]},
            "URL": {"url": url},
            "ë¶„ë¥˜": {"multi_select": [{"name": category}]},
            "ìˆ˜ì§‘ì¼": {"date": {"start": today_str}},
            "ìš”ì•½": {"rich_text": [{"text": {"content": summary_text}}]}
        }
        notion.pages.create(parent={"database_id": DATABASE_ID}, properties=new_page)
        print(f"âœ… [ì—…ë¡œë“œ ì„±ê³µ!] ì¹´í…Œê³ ë¦¬: {category} | ì œëª©: {title}")
    except Exception as e:
        print(f"âŒ [ì—…ë¡œë“œ ì‹¤íŒ¨] ì œëª©: {title} | ì˜¤ë¥˜: {e}")
        pass

# --- 6. [ìˆ˜ì •ë¨] ë©”ì¸ ì‹¤í–‰ ë¡œì§ (ì•ˆì •ì„± ê°•í™”) ---
def fetch_and_filter_news():
    print("="*30)
    print("ğŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘ ë° í•„í„°ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("="*30)
    
    existing_urls = get_existing_urls(days_to_check=3) 
    total_uploaded = 0
    total_skipped = 0
    
    for category_guess, rss_url in RSS_FEEDS.items():
        print(f"\n--- [{category_guess}] ì¹´í…Œê³ ë¦¬ í”¼ë“œ í™•ì¸ ì¤‘... ---")
        
        # ğŸ”½ğŸ”½ğŸ”½ [í•µì‹¬ ìˆ˜ì •] ğŸ”½ğŸ”½ğŸ”½
        # RSS í”¼ë“œ í•˜ë‚˜ê°€ ì˜¤ë¥˜ë‚˜ë„ ì „ì²´ ìŠ¤í¬ë¦½íŠ¸ê°€ ë©ˆì¶”ì§€ ì•Šë„ë¡ try...exceptë¡œ ê°ìŒ‰ë‹ˆë‹¤.
        try:
            feed = feedparser.parse(rss_url)
            
            if not feed.entries:
                print("  (ìˆ˜ì§‘ëœ ê¸°ì‚¬ ì—†ìŒ)")
                continue

            for item in feed.entries:
                title = item.title
                link = item.link
                
                if link in existing_urls:
                    total_skipped += 1
                    continue 

                summary = item.get("summary", "") 
                content_to_check = title + " " + summary
                
                found_category = None
                for category_name, keywords_list in KEYWORDS.items():
                    if any(keyword.lower() in content_to_check.lower() for keyword in keywords_list):
                        found_category = category_name
                        break 
                
                if found_category:
                    add_to_notion(title, link, found_category, summary)
                    existing_urls.add(link)
                    total_uploaded += 1
        
        except Exception as e:
            print(f"âŒ [í”¼ë“œ ì˜¤ë¥˜!] '{category_guess}' í”¼ë“œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("  (ë‹¤ìŒ í”¼ë“œë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.)")
            pass # ì´ í”¼ë“œëŠ” ê±´ë„ˆë›°ê³  ë‹¤ìŒ í”¼ë“œë¡œ ë„˜ì–´ê°
        # ğŸ”¼ğŸ”¼ğŸ”¼ [í•µì‹¬ ìˆ˜ì •] ğŸ”¼ğŸ”¼ğŸ”¼
            
    print("\n" + "="*30)
    print(f"ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ.")
    print(f"  - ì‹ ê·œ ì—…ë¡œë“œ: {total_uploaded}ê°œ")
    print(f"  - ì¤‘ë³µ ìŠ¤í‚µ: {total_skipped}ê°œ")
    print("="*30)

# --- ğŸš€ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ---
if __name__ == "__main__":
    fetch_and_filter_news()
